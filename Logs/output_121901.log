nohup: ignoring input
Using device: cuda
{'optimizer': 'SGD', 'nn_model': 'CIFAR10_convnet', 'dataset': 'CIFAR10', 'n_epoch': 100, 'lr': 0.01, 'batch_size': 64, 'weight_decay': 0.0, 'exp_name': '121901', 'print_every': 1, 'ratio': 1.0, 'temperature': 0.5}
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/CIFAR10/cifar-10-python.tar.gz
  0%|          | 0.00/170M [00:00<?, ?B/s]  0%|          | 197k/170M [00:00<01:39, 1.71MB/s]  2%|▏         | 3.05M/170M [00:00<00:10, 16.5MB/s]  5%|▍         | 8.52M/170M [00:00<00:04, 32.5MB/s]  9%|▊         | 14.7M/170M [00:00<00:03, 43.7MB/s] 12%|█▏        | 20.5M/170M [00:00<00:03, 47.9MB/s] 16%|█▌        | 26.5M/170M [00:00<00:02, 51.8MB/s] 19%|█▉        | 32.7M/170M [00:00<00:02, 53.9MB/s] 23%|██▎       | 38.7M/170M [00:00<00:02, 55.8MB/s] 26%|██▋       | 45.2M/170M [00:00<00:02, 58.3MB/s] 30%|██▉       | 51.0M/170M [00:01<00:02, 58.3MB/s] 34%|███▎      | 57.3M/170M [00:01<00:01, 59.6MB/s] 37%|███▋      | 63.7M/170M [00:01<00:01, 60.7MB/s] 41%|████      | 69.8M/170M [00:01<00:01, 60.8MB/s] 45%|████▍     | 76.3M/170M [00:01<00:01, 62.1MB/s] 49%|████▊     | 82.7M/170M [00:01<00:01, 62.6MB/s] 52%|█████▏    | 89.1M/170M [00:01<00:01, 62.7MB/s] 56%|█████▋    | 95.9M/170M [00:01<00:01, 64.2MB/s] 60%|██████    | 102M/170M [00:01<00:01, 64.0MB/s]  64%|██████▍   | 109M/170M [00:01<00:00, 64.6MB/s] 68%|██████▊   | 116M/170M [00:02<00:00, 65.7MB/s] 72%|███████▏  | 122M/170M [00:02<00:00, 65.7MB/s] 76%|███████▌  | 129M/170M [00:02<00:00, 66.2MB/s] 80%|███████▉  | 136M/170M [00:02<00:00, 66.9MB/s] 84%|████████▎ | 143M/170M [00:02<00:00, 66.9MB/s] 88%|████████▊ | 150M/170M [00:02<00:00, 67.9MB/s] 92%|█████████▏| 157M/170M [00:02<00:00, 68.3MB/s] 96%|█████████▌| 164M/170M [00:02<00:00, 68.1MB/s]100%|█████████▉| 170M/170M [00:02<00:00, 68.0MB/s]100%|██████████| 170M/170M [00:02<00:00, 59.9MB/s]
Extracting data/CIFAR10/cifar-10-python.tar.gz to data/CIFAR10
Files already downloaded and verified
Using optimizer: SGD_Simple
full gradient norm:  0.001007226062938571
/local/storage/tian/OptML-SVRG-PyTorch/sgd.py:35: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1642.)
  p.data.add_(-group['lr'], d_p)
Iteration:  10
loss:  2.3054087162017822 acc:  0.109375 grads:  tensor([ 0.0002,  0.0001,  0.0001,  ..., -0.0012, -0.0016,  0.0013],
       device='cuda:2')
